{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "environment": {
      "name": "common-cu101.m48",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/base-cu101:m48"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Correct notebook.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/v-vedantha/Project-8/blob/master/Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6TZ96pnE6_N",
        "outputId": "ce8062b1-1616-4de7-94ed-0b73e99a8188"
      },
      "source": [
        "%pylab inline\n",
        "from pprint import pprint\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import plotly.express as px\n",
        "from scipy.stats import cauchy\n",
        "import plotly.graph_objects as go\n",
        "from scipy.stats import norm\n",
        "from iminuit import Minuit, describe\n",
        "%matplotlib inline\n",
        "from plotly.subplots import make_subplots\n",
        "from iminuit.util import make_func_code"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNArDaykE6_S"
      },
      "source": [
        "# Downloads the data from files for figure 1\n",
        "def createF_1():\n",
        "    \n",
        "    f = open(\"DataasCSV.txt\", \"r\")\n",
        "    f_ = open(\"errors_fig1.txt\", \"r\")\n",
        "    content_=f_.read().split()\n",
        "    content = f.read()\n",
        "    x = content.split()\n",
        "    inputs = []\n",
        "    outputs = []\n",
        "    errors=[]\n",
        "    print(len(x), len(content_))\n",
        "    n = 0\n",
        "    while n<len(x):\n",
        "        if(n%2 == 0):\n",
        "            inputs.append(float(x[n]))\n",
        "        else:\n",
        "            outputs.append(float(x[n]))\n",
        "            errors.append(float(content_[int(n/2)]))\n",
        "\n",
        "        n += 1\n",
        "    return (np.asarray(inputs), np.asarray(outputs), np.asarray(errors))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riChE7e9E6_V"
      },
      "source": [
        "# Downloads Figure 2 data from files\n",
        "def createF_2():\n",
        "    \n",
        "    f = open(\"Data2.txt\", \"r\")\n",
        "    f_ = open(\"errors_fig2.txt\", \"r\")\n",
        "    content_=f_.read().split()\n",
        "    content = f.read()\n",
        "    x = content.split()\n",
        "    inputs = []\n",
        "    outputs = []\n",
        "    errors=[]\n",
        "    print(len(x), len(content_))\n",
        "    n = 0\n",
        "    while n<len(x):\n",
        "        if(n%2 == 0):\n",
        "            inputs.append(float(x[n]))\n",
        "        else:\n",
        "            outputs.append(float(x[n]))\n",
        "            errors.append(float(content_[int(n/2)]))\n",
        "\n",
        "        n += 1\n",
        "    return (np.asarray(inputs), np.asarray(outputs), np.asarray(errors))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBVryLXKE6_X",
        "outputId": "8d33f389-a53c-4f74-d108-8e17876a2875"
      },
      "source": [
        "# Saves figure 1 and figure 2 data \n",
        "# REALIN is the x-values (i.e. the inputs)\n",
        "# REALOUT is the y-values (i.e. the outputs)\n",
        "# REALERRORS is the error bars on y for a given x.\n",
        "\n",
        "REALIN_1, REALOP_1, REALERROR_1 = createF_1()\n",
        "REALIN_2, REALOP_2, REALERROR_2 = createF_2()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "264 132\n",
            "292 146\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZISYK38E6_a"
      },
      "source": [
        "# Represents the energies of the lorentzians for Figure 1\n",
        "LORENTZIANS_ENERGY_1 = np.array([[ 0,   0.0000,   0.0000,   0.0000,   0.0000],\n",
        "        [ 19.8,  21.7,  22.8805,  23.639,  0],\n",
        "        [ 36.3,  38.744,  40.2182,  41.1752,   0.0000],\n",
        "        [117,   0.0000,   0.0000,   0.0000,   0.0000],\n",
        "        [255.4,   0.0000,   0.0000,   0.0000,   0.0000]])\n",
        "\n",
        "# Represents the energies of the lorentzians in Figure 2\n",
        "LORENTZIANS_ENERGY_2 = np.array([[ 0,   0.0000,   0.0000,   0.0000,   0.0000],\n",
        "        [ 19.8,  21.7,  22.8805,  23.639,  0],\n",
        "        [ 36.3,  38.744,  40.2182,  41.1752,   0.0000],\n",
        "        [117,   0.0000,   0.0000,   0.0000,   0.0000],\n",
        "        [255.4,   0.0000,   0.0000,   0.0000,   0.0000]])\n",
        "\n",
        "# Placeholder for another technique we were trying at the time\n",
        "LOCATION_THREE_HALFS = np.array([[]])\n",
        "\n",
        "# Stores the magnitudes (intensities) of each lorentzian.\n",
        "LORENTZIANS_MAGNITUDES = np.array([[100, 0, 0, 0, 0],\n",
        "                                     [13.05, 2.5, .9, 1.8, 0],\n",
        "                                     [2, 0.4, 0.1, 0.1, 0],\n",
        "                                     [1.3, 0, 0, 0, 0],\n",
        "                                     [.1, 0, 0, 0, 0]])\n",
        "\n",
        "# Since there is spin orbit splitting, we have to store the spin orbit splitting energies for each lorentzian.\n",
        "deltas_l=np.array([[ 0,   0.0000,   0.0000,   0.0000,   0.0000],\n",
        "        [ .69, .69, .69, .69, .69],\n",
        "        [ 0,0,0,0,   0.0000],\n",
        "        [1.49,   0.0000,   0.0000,   0.0000,   0.0000],\n",
        "        [9,   0.0000,   0.0000,   0.0000,   0.0000]])\n",
        "\n",
        "# Stores spin orbit splitting energies for shakeoffs\n",
        "deltas_a= np.array([[0], [.69], [0], [1.49], [9]])\n",
        "\n",
        "# Stores the relative energy of spin orbits for the shakeoffs\n",
        "factors_half_a = np.array([[0], [1.0], [1.0], [2.0], [1.0]])\n",
        "factors_lower_a = np.array([[0.0], [2.0], [1.0], [3.0], [2.0]])\n",
        "\n",
        "# Stores the relative energy of spin orbits for lorentzians\n",
        "factors_half_l = np.array([[ 1,   0.0000,   0.0000,   0.0000,   0.0000],\n",
        "        [ 1, 1, 1, 1, 1],\n",
        "        [ 1.0,1.0,1.0,1.0,   0.0000],\n",
        "        [2,   0.0000,   0.0000,   0.0000,   0.0000],\n",
        "        [1*1.02,   0.0000,   0.0000,   0.0000,   0.0000]])\n",
        "factors_lower_l = np.array([[ 0,   0.0000,   0.0000,   0.0000,   0.0000],\n",
        "        [ 2,  2, 2, 2, 2],\n",
        "        [ 0,0,0,0,   0.0000],\n",
        "        [3,   0.0000,   0.0000,   0.0000,   0.0000],\n",
        "        [2,   0.0000,   0.0000,   0.0000,   0.0000]])\n",
        "\n",
        "# Stores the dropoff energies (the x values) for the shakeoffs\n",
        "DROPOFF_ENERGY = np.array([[0.00001], [26.1], [44.3], [135], [267]])\n",
        "\n",
        "# Stores a rough estimate of the magnitudes of the dropoffs\n",
        "# Not necessary, but can provide insights when fitting.\n",
        "DROPOFF_MAGNITUDES = np.array([[0], [7], [1.3], [3.8], [1.2]])\n",
        "\n",
        "# Sets up parameters to calculate the lorentzians, including full with half maximums and gammas.\n",
        "DROPOFF_NUM = 5\n",
        "FWHM_1 = np.array([[2.7],\n",
        "                    [2.7],\n",
        "                    [3.1],\n",
        "                    [2.77],\n",
        "                    [3.93]])\n",
        "GAMMA_1 = FWHM_1/2\n",
        "FWHM_2 = np.array([[2.7],\n",
        "                    [2.7],\n",
        "                    [3.1],\n",
        "                    [2.77],\n",
        "                    [4.022]])\n",
        "GAMMA_2 = FWHM_2/2\n",
        "\n",
        "# Estimated main energies from paper. We find better fits and update these.\n",
        "MAIN_ENERGY_1 = 17823.3\n",
        "MAIN_ENERGY_2 = 900.6\n",
        "\n",
        "# Increasing NUM_FIXED increases the precision of the convolution, however, it also takes longer to compute.\n",
        "# Dictates the number of elements ot use in convolution calculation.\n",
        "NUM_GAUSSIANS = 1\n",
        "NUM_FIXED=800\n",
        "\n",
        "# Estimated standard deviations (widths) of core state.\n",
        "STD_1 = 23.5/2.355\n",
        "STD_2 = 5.9/2.355\n",
        "\n",
        "# Scaled heights of the two figures\n",
        "H_1 = .178\n",
        "H_2 = 25.7\n",
        "\n",
        "\n",
        "# Calculates the convolution matrices\n",
        "G = np.linspace(-2.32, 2.32, NUM_FIXED)\n",
        "GM=np.asarray(norm.pdf(G))\n",
        "\n",
        "# Shakeup precalculated variables. Allows you to calculate the spin states more cleanly.\n",
        "LORENTZIANS_DISTRIBUTIONS_1 = np.zeros((5,1))\n",
        "LORENTZIANS_DISTRIBUTIONS_MAGNITUDES_1 = np.ones((5,1))\n",
        "LORENTZIANS_DISTRIBUTIONS_2 = np.zeros((5,1))\n",
        "LORENTZIANS_DISTRIBUTIONS_MAGNITUDES_2 = np.ones((5,1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2hSzpMGE6_c"
      },
      "source": [
        "# Contains all methods relating to calculating the spectra and plotting\n",
        "class Model():\n",
        "    def __init__(self, REALIN_1, REALOP_1, REALERROR_1, REALIN_2, REALOP_2, REALERROR_2):\n",
        "        self.REALIN_1=REALIN_1 \n",
        "        self.REALOP_1=REALOP_1\n",
        "        self.REALERROR_1=REALERROR_1\n",
        "        self.REALIN_2=REALIN_2        \n",
        "        self.REALOP_2=REALOP_2\n",
        "        self.REALERROR_2=REALERROR_2\n",
        "        \n",
        "        \n",
        "    # This stores the 6th factor in the shakeoff term\n",
        "    # The goal of this factor is to reduce the correlation between the shakeoff\n",
        "    # parameters of intensity and slope.\n",
        "    # Also must have zero units\n",
        "    def factor_6(self, EB, DROPOFF_ENERGY_, version, params):\n",
        "        \n",
        "        # The function we came up with for the best correlation reduction term\n",
        "        r = np.log(EB.flatten()[:5]/DROPOFF_ENERGY_.flatten())\n",
        "        if version == True:\n",
        "            return r.reshape(1,1,-1,1)\n",
        "        else:\n",
        "            # An older version of the function above\n",
        "            params[:5] = params[:5]/np.log(EB.flatten()[:5])/r\n",
        "            print(params)\n",
        "            return params\n",
        "        \n",
        "    # The shakeoff term consists of five factors which we split up\n",
        "    def get_factors(self, n_prime, intratio, energy, MAIN_ENERGY, drop, EB):\n",
        "        \n",
        "        #\n",
        "        # The first four factors are part of the levinger function from the cited paper\n",
        "        # The dropoff factor ensures that the levinger function is cutoff without making it a discontinuous function\n",
        "        # The fifth factor is a normalizing factor which undoes the relationship between E_B and the intensity.\n",
        "        # The sixth factor is the factor 6 above. We were testing out systems without it\n",
        "        # Returns the levinger functions for all 5 dropoffs\n",
        "        # Shape : N, 50, 5, 50\n",
        "        #\n",
        "        \n",
        "        factor_1 = np.power(1-np.exp(-2*3.141592 * n_prime),-1)\n",
        "        \n",
        "        factor_2 = np.power(n_prime,8)\n",
        "        \n",
        "        #\n",
        "        # We do not need to calculate this value, because of the fix that Dr. Robertson found (in paper).\n",
        "        # Essentially, he found a simplification for the shakeoff amplitudes that works well, which removes \n",
        "        # this somewhat arbitrary technique to cut off the shakeoffs at their peak (with convolution)\n",
        "        #\n",
        "        #dropoff_factor = (np.tanh(99999 * (energy.reshape(-1,NUM_FIXED, DROPOFF_NUM*2, NUM_GAUSSIANS) - (MAIN_ENERGY-drop)))+1) * 900 + 1\n",
        "        factor_3 = np.power(np.power(n_prime, 2)+1, -4)\n",
        "        \n",
        "        factor_4 = np.exp(-4*n_prime*np.arctan(1/n_prime))\n",
        "        \n",
        "        factor_5 = 1/np.power(EB.reshape(1,1,-1,1), .5)\n",
        "        \n",
        "        # Returns the product of those factors.\n",
        "        return factor_1*factor_2*factor_3*factor_4*intratio*np.concatenate((DROPOFF_MAGNITUDES.reshape(1,1,-1,1), DROPOFF_MAGNITUDES.reshape(1,1,-1,1)), axis=2) * factor_5# * factor_6\n",
        "\n",
        "    def amplitude(self, energy, whichPlot, relative_magnitudes_a, relative_magnitudes_l, X_Shift, E_B,  H1, H2, ME1, ME2):\n",
        "        \n",
        "        # Decides which plot we are using\n",
        "        if whichPlot == 1:\n",
        "            MAIN_ENERGY = ME1\n",
        "            relative_magnitudes_ = relative_magnitudes_a*H1\n",
        "        if whichPlot == 2:\n",
        "            relative_magnitudes_ = relative_magnitudes_a*H2\n",
        "            MAIN_ENERGY = ME2\n",
        "\n",
        "\n",
        "        # Shifts the entire spectrum according to the energy of the core\n",
        "        DROPOFF_ENERGY_ = DROPOFF_ENERGY+X_Shift\n",
        "        \n",
        "        \n",
        "        # We concenate both spin states to track them easier.\n",
        "        # Drop stores the dropoff energy (the peak in the unconvolved spectrum) of each shakeoff\n",
        "        drop = np.concatenate((DROPOFF_ENERGY_.reshape(1,1,-1,1) + deltas_a.reshape(1,1,-1,1), DROPOFF_ENERGY_.reshape(1,1,-1,1)), axis=2)\n",
        "\n",
        "        # W stores the energy of each shakeoff.\n",
        "        W = MAIN_ENERGY - drop - energy.reshape(-1,NUM_FIXED,DROPOFF_NUM*2, NUM_GAUSSIANS)\n",
        "\n",
        "        # Calculates n' from the levinger paper.\n",
        "        n_prime = np.sqrt(np.concatenate((E_B.reshape(1,1,-1, 1), E_B.reshape(1,1,-1,1)), axis=2)/np.abs(W+1e-4))\n",
        "\n",
        "        \n",
        "        # Each spin state has its own scaling factor, stored here.\n",
        "        factors_final = np.concatenate((factors_half_a, factors_lower_a))\n",
        "        \n",
        "        # Generates the convolved spectrum with the factors for the spin states above.\n",
        "        spectrum = self.get_factors(n_prime, factors_final, energy, MAIN_ENERGY,drop, np.concatenate((E_B.reshape(1,1,-1, 1), E_B.reshape(1,1,-1,1)), axis=2))*np.concatenate((relative_magnitudes_.reshape(1,1,-1,1), relative_magnitudes_.reshape(1,1,-1,1)), axis=2)\n",
        "        \n",
        "        # The fix we've applied to smoothen the peak more simply. Noted in paper.\n",
        "        spectrum_convolved = spectrum * (.25 + 1/6.283184*np.arctan(2*W/np.concatenate((GAMMA_1.reshape(1,1,-1,1), GAMMA_2.reshape(1,1,-1,1)), axis=2)))\n",
        "        \n",
        "        # Return the sum of the two spin states.\n",
        "        return spectrum_convolved\n",
        "        \n",
        "    \n",
        "    def lorentzians(self, energy, whichPlot, relative_magnitudes_a, relative_magnitudes_l, X_Shift, E_B,H1, H2, ME1, ME2):\n",
        "\n",
        "        # Decides which figure we are using\n",
        "        if whichPlot == 1:\n",
        "            MAIN_ENERGY = ME1\n",
        "            LORENTZIANS_ENERGY = LORENTZIANS_ENERGY_1+X_Shift\n",
        "            relative_magnitudes_ = relative_magnitudes_l*H1            \n",
        "        if whichPlot == 2:\n",
        "            LORENTZIANS_ENERGY=LORENTZIANS_ENERGY_2+X_Shift\n",
        "            MAIN_ENERGY = ME2\n",
        "            relative_magnitudes_ = relative_magnitudes_l*H2\n",
        "\n",
        "        # Creates all the lorentzians using the default lorentzian formula with the applied heights and widths for the higher energy spin state (bottom comes from the fact that it appears below that spin state on the plot)\n",
        "        bottom = (energy.reshape(-1,NUM_FIXED,1,1)-(MAIN_ENERGY - LORENTZIANS_ENERGY.reshape(1,1,DROPOFF_NUM,-1)-deltas_l.reshape(1,1,DROPOFF_NUM,-1)))**2 + GAMMA_1.reshape(1,1,DROPOFF_NUM, 1)**2\n",
        "        \n",
        "        # Scales the lorentzian according to the scaling parameters we train and the default spin state parameters.\n",
        "        scaling_factor = relative_magnitudes_.reshape(1,1,-1,1) * LORENTZIANS_MAGNITUDES.reshape(1,1,DROPOFF_NUM,-1) * GAMMA_1.reshape(1,1,DROPOFF_NUM,1)**2\n",
        "        \n",
        "        # Repeats above technique for the higher lorentzians.\n",
        "        bottom_2 = (energy.reshape(-1,NUM_FIXED,1,1)-(MAIN_ENERGY - LORENTZIANS_ENERGY.reshape(1,1,DROPOFF_NUM,-1)))**2 + GAMMA_2.reshape(1,1,DROPOFF_NUM, 1)**2\n",
        "        scaling_factor_2 = relative_magnitudes_.reshape(1,1,-1,1) * LORENTZIANS_MAGNITUDES.reshape(1,1,DROPOFF_NUM,-1) * GAMMA_2.reshape(1,1,DROPOFF_NUM,1)**2\n",
        "        \n",
        "        # Combines the two lorentzians, but does not sum them up because we need to calculate their convolutions separately\n",
        "        return np.concatenate((scaling_factor * factors_half_l.reshape(1,1,DROPOFF_NUM,-1)/bottom, scaling_factor_2 * factors_lower_l.reshape(1,1,DROPOFF_NUM,-1)/bottom_2), axis=3)\n",
        "\n",
        "    # Generates the spectrum of shakeups and shakeoffs and applies appropriate convolution to them.\n",
        "    def gaussianify(self, energy, whichPlot, useGaussian, useLorentzian, useAmplitude, relative_magnitudes_a, relative_magnitudes_l, X_Shift, E_B , H1, H2, ME1, ME2, STD_1, STD_2, lorentzian=1):\n",
        "        \n",
        "        # useX represents wether we use that term in our calculation. Lorentzians=Shakeup, Amplitude=Shakeoff, Gaussian=Gaussian convolution\n",
        "        # Fit the height, ME, and the width by using about 2 standard deviations \n",
        "        # Fit the rest keeping the height, ME, and width constant\n",
        "        if whichPlot == 1:\n",
        "            \n",
        "            GAUSSIAN_MAGNITUDES = GM/STD_1\n",
        "            GAUSSIAN = G*STD_1\n",
        "            WIDTH_1 = GAUSSIAN[1] - GAUSSIAN[0]\n",
        "            GAUSSIAN_MAGNITUDES *= WIDTH_1\n",
        "        if whichPlot == 2:\n",
        "            \n",
        "            GAUSSIAN_MAGNITUDES = GM/STD_2\n",
        "            GAUSSIAN = G*STD_2\n",
        "            WIDTH_2 = GAUSSIAN[1] - GAUSSIAN[0]\n",
        "            GAUSSIAN_MAGNITUDES *= WIDTH_2\n",
        "\n",
        "        # This is the energy input (the x's) scaled appropriately.\n",
        "        inner = useGaussian*GAUSSIAN.reshape(1,-1,1,1) + energy.reshape(-1,1,1,1) + 1*np.concatenate((LORENTZIANS_DISTRIBUTIONS_1.reshape(1,1,DROPOFF_NUM,NUM_GAUSSIANS), LORENTZIANS_DISTRIBUTIONS_2.reshape(1,1,DROPOFF_NUM,NUM_GAUSSIANS)), axis=2)\n",
        "\n",
        "        # This is the levinger functions when run on the inputs\n",
        "        mid_amp = self.amplitude(inner, whichPlot, relative_magnitudes_a, relative_magnitudes_l, X_Shift, E_B, H1, H2, ME1, ME2)\n",
        "        \n",
        "        # This is the levinger functions summed up with lorentzian convolution\n",
        "        amp_1 = np.sum(mid_amp* np.concatenate((LORENTZIANS_DISTRIBUTIONS_MAGNITUDES_1.reshape(1,1,DROPOFF_NUM,NUM_GAUSSIANS), LORENTZIANS_DISTRIBUTIONS_MAGNITUDES_2.reshape(1,1,DROPOFF_NUM,NUM_GAUSSIANS)), axis=2), (2,3))\n",
        "        \n",
        "        # This is the gaussian convolution applied to the levinger functions post-convolution\n",
        "        amp = np.sum(amp_1 * GAUSSIAN_MAGNITUDES.reshape(1, -1), 1)\n",
        "        \n",
        "        # This is the gaussian convolution applied to the lorentzian\n",
        "        lor = self.lorentzians(useGaussian*GAUSSIAN.reshape(1,-1) + energy.reshape(-1,1), whichPlot, relative_magnitudes_a, relative_magnitudes_l, X_Shift, E_B, H1, H2, ME1, ME2) * GAUSSIAN_MAGNITUDES.reshape(1,-1,1,1)\n",
        "        \n",
        "        # Summing up the lorentzians\n",
        "        lor = np.sum(lor, (1,2,3))\n",
        "        \n",
        "        # Returns the final spectrum\n",
        "        return useAmplitude*amp + useLorentzian*lor\n",
        "    \n",
        "    # Plots the spectrum.\n",
        "    def plot(self, whichPlot, min, max, par, label, lower, height, l=1,plotG=False, plotHG=False, plotF=False, plotDif=False, useLorentzian=1, useAmplitude=1):\n",
        "        # Whichplot is the figure you want to plot\n",
        "        # min, max are the ranges of the figure\n",
        "        # par is the parameters\n",
        "        # label is the y axis labels\n",
        "        # height is the height of the grey line representing the core-shakeoff to rest of the graph transition\n",
        "\n",
        "        # Decides on which plot to use\n",
        "        if whichPlot == 1:\n",
        "            REALIN = REALIN_1\n",
        "            REALOP = REALOP_1\n",
        "            REALERROR=REALERROR_1\n",
        "        else:\n",
        "            REALIN=REALIN_2\n",
        "            REALOP=REALOP_2\n",
        "            REALERROR=REALERROR_2\n",
        "            \n",
        "        # \n",
        "        # Plots only in a certain range identified by min and max\n",
        "        #\n",
        "        fs=35\n",
        "        curr_min = -1\n",
        "        curr_max = 200000\n",
        "        index_min = 0\n",
        "        index_max = 0\n",
        "        for i in REALIN:\n",
        "\n",
        "            if i < min:\n",
        "                index_min+=1\n",
        "\n",
        "            if i < max:\n",
        "                index_max+=1\n",
        "\n",
        "        # Creates the figure we will plot on.\n",
        "        fig = make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0, row_heights=[66,33])\n",
        "        fig.update_layout(template=\"simple_white\", font=dict(family=\"Times New Roman\"size= fs,color=\"#000000\"), showlegend=False)\n",
        "        fig.update_yaxes(title_text=label, row=1, linewidth=2, col=1, mirror=True, ticks='outside', showline=True)\n",
        "        fig.update_yaxes(title_text=\"Residuals\", row=2, col=1, mirror=True,linewidth=2, ticks='outside', showline=True)\n",
        "        fig.update_xaxes(title_text=\"Electron Energy (eV)\", row=2, col=1, linewidth=2, tickformat=\".,\")\n",
        "        fig.update_xaxes(row=1, col=1, mirror=True, ticks='outside',linewidth=2,  showline=True)\n",
        "        fig.update_layout(autosize=False,width=1000,height=1000)\n",
        "        fig.add_shape(go.layout.Shape(type=\"line\",x0=REALIN[index_min],y0=0,x1=REALIN[index_max-1],y1=0,line=dict(color=\"Black\",width=2,dash=\"dot\",)), row=1,col=1)\n",
        "        fig.add_shape(go.layout.Shape(type=\"line\",x0=lower,y0=-4,x1=lower,y1=4,line=dictcolor=\"Black\",width=3)), row=2, col=1)\n",
        "        fig.add_shape(go.layout.Shape(type=\"line\",x0=lower,y0=0,x1=lower,y1=height,line=dict(color=\"Black\",width=3), row=1, col=1)\n",
        "        fig.add_shape(go.layout.Shape(type=\"line\",x0=REALIN[index_min],y0=0,x1=REALIN[index_max-1], y1=0, line=dict(color=\"Black\",width=2,dash=\"dot\",)), row=2,col=1)\n",
        "        \n",
        "        # HG is the convolved version of the spectrum\n",
        "        hg = self.gaussianify(REALIN, whichPlot, 1, useLorentzian, 1, par[0:5], par[5:10], par[10:15].reshape(5,1), par[15:20], par[20], par[21], par[22], par[23], par[24], par[25], lorentzian=l)\n",
        "        \n",
        "        # Plots the graph with logn scaling on y axis to better see structure.\n",
        "        if plotG:\n",
        "            \n",
        "            # Store the energies but with a lot more points plotted to see finer detail\n",
        "            rr=np.linspace(17400, 17900, 700)\n",
        "            \n",
        "            # Calculates the scaled graph. g, g2 are used so the y-axis scalin has numbers close to 1\n",
        "            g = self.gaussianify(rr, whichPlot, 0, 0, 1, par[0:5], par[5:10], par[10:15].reshape(5,1), par[15:20], par[20], par[21], par[22], par[23], par[24], par[25], lorentzian=l)\n",
        "            g2=self.gaussianify(rr, whichPlot, 0, 1, 1, par[0:5], par[5:10], par[10:15].reshape(5,1), par[15:20], par[20], par[21], par[22], par[23], par[24], par[25], lorentzian=l)\n",
        "            s = np.sum(g2)\n",
        "            g=g/s\n",
        "            g2=g2/s\n",
        "\n",
        "            \n",
        "            # Creates the graph\n",
        "            fig = make_subplots(rows=1, cols=1, shared_xaxes=True, vertical_spacing=0)\n",
        "            fig.update_layout(template=\"simple_white\", font=dict(family=\"Times New Roman\",size= fs,color=\"#000000\"), showlegend=False)\n",
        "            fig.update_yaxes(title_text=\"Intensity, %\", row=1, linewidth=2, col=1, mirror=True,ticks='outside',showline=True)\n",
        "            fig.update_xaxes(title_text=\"Electron Energy (eV)\", row=2, col=1, linewidth=2, tickformat=\".,\")\n",
        "            fig.update_xaxes(row=1, col=1, mirror=True, ticks='outside',linewidth=2,  showline=True)\n",
        "            fig.update_layout(autosize=False,width=1000,height=1000)\n",
        "            fig.add_trace(go.Scatter(x=rr, y=g,mode='lines'))\n",
        "            fig.add_trace(go.Scatter(x=rr, y=g2,mode='lines'))\n",
        "\n",
        "        # Plots the graph without scaling.\n",
        "        if plotDif:\n",
        "            fig.add_trace(go.Scatter(x=np.asarray(REALIN[index_min:index_max]), y=np.asarray((-hg[index_min:index_max] + REALOP[index_min:index_max])/REALERROR[index_min:index_max]),\n",
        "                                mode='markers'), row=2, col=1)\n",
        "            fig.add_trace(go.Scatter(x=np.asarray(REALIN[index_min:index_max]), y=np.asarray(hg[index_min:index_max]), line=dict(color='royalblue'),\n",
        "                                mode='lines'))\n",
        "            fig.add_trace(go.Scatter(x=np.asarray(REALIN[index_min:index_max]), y=np.asarray(REALOP[index_min:index_max]), error_y=dict(\n",
        "                                type='data', # value of error bar given in data coordinates\n",
        "                                array=np.asarray(REALERROR[index_min:index_max]),\n",
        "                                visible=True),\n",
        "                                mode='markers'))\n",
        "        fig.show()\n",
        "        \n",
        "    # Calculates the squared error loss for iminuit to fit on\n",
        "    def loss(self, par_):  \n",
        "        \n",
        "        # We're taking iminuit parameters and converting them into a numpy array to make it easier to work with \n",
        "        par = np.asarray(par_)\n",
        "\n",
        "        # Calculates the convolved spectrums for both figures\n",
        "        hg_1 = self.gaussianify(REALIN_1, 1, 1, 1, 1, par[0:5],  par[5:10], par[10:15].reshape(5,1) ,par[15:20], par[20], par[21], par[22], par[23], par[24], par[25])\n",
        "        hg_2 = self.gaussianify(REALIN_2, 2, 1, 1, 1, par[0:5],  par[5:10], par[10:15].reshape(5,1) ,par[15:20], par[20], par[21], par[22], par[23], par[24], par[25])\n",
        "        \n",
        "        # Computes the chi square value, multiplying factors add weightings.\n",
        "        # The commented out bounds are the bounds for different regions. Core, Shakeoffs, and so on. Only used to make it easier to switch between them when testing.\n",
        "        loss_1 = np.power((REALOP_1-hg_1)/(REALERROR_1),2) [:90]#[:90]#[96:125]#[:-11]#[96:125]#[:90]#\n",
        "        loss_2 = np.power((REALOP_2-hg_2)/(REALERROR_2),2) [:101]#[:101]#[110:135]#[:-5]#[101:120]#[:103]\n",
        "    \n",
        "        # The chi square loss is summed for both figures\n",
        "        loss=np.sum(loss_1) +np.sum(loss_2)\n",
        "\n",
        "        # Print out to see progress, and store information of notebook crashes\n",
        "        print(loss)\n",
        "        print(repr(par))\n",
        "        return loss\n",
        "    \n",
        "    # Gets intensity of a particular state.\n",
        "    def get_intensities(self, par_, whichPlot, REALIN):\n",
        "        \n",
        "        # When specifying inputs, set all variables corresponging to energies to 0 except the one whose intensity you are trying to calculate\n",
        "        par = np.asarray(par_)\n",
        "        hg = self.gaussianify(REALIN, whichPlot, 1, 1, 1, par[0:5], par[5:10], par[10:15].reshape(5,1), par[15:20], par[20], par[21], par[22], par[23], par[24], par[25],  lorentzian=1)\n",
        "        return np.sum(hg)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDCZs24IE6_h"
      },
      "source": [
        "# Initialize model\n",
        "M = Model(REALIN_1, REALOP_1, REALERROR_1, REALIN_2, REALOP_2, REALERROR_2)\n",
        "\n",
        "# Core state \"hyperparameters\"\n",
        "# Same as above, but moved down for easier editing.\n",
        "STD_1 = 23.5/2.355\n",
        "STD_2 = 5.9/2.355\n",
        "MAIN_ENERGY_1 = 17823.3\n",
        "MAIN_ENERGY_2 = 900.6\n",
        "H_1 = .178\n",
        "H_2 = 25.7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbH8tEzbNsr8"
      },
      "source": [
        "Contains example values.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Slo4rFUcE6_k",
        "outputId": "d55be75d-6cd9-47bd-a4e7-0458e80a6e8f"
      },
      "source": [
        "# Example local minimum. May not be fully up to date.\n",
        "m_binned = Minuit.from_array_func(M.loss, (4.34294482e+00,  2.65537599e+01,  6.92902835e+01,  1.41800375e+00,\n",
        "        1.70465972e+00,  1.04891547e+00,  5.26598850e-01,  8.23968722e-01,\n",
        "        9.20775549e-01,  3.84986853e-01,  0.00000000e+00,  0.00000000e+00,\n",
        "        0.00000000e+00,  9.70000000e+00, -1.68140372e+01,  1.00000000e+01,\n",
        "        9.11478559e+00,  3.82400862e+01,  1.93461207e+02,  3.03461383e+03,\n",
        "        1.79129666e-01,  2.57777795e+01,  1.78226541e+04,  9.00499209e+02,\n",
        "        9.85870946e+00,  2.62788239e+00), pedantic=False, error_x12=0.1, limit_x0=(0,None),limit_x1=(0,None), \n",
        "                                  limit_x2=(0,None), limit_x3=(0,None), limit_x4=(0,None), limit_x5=(0,None), limit_x6=(0,None), limit_x7=(0,None), fix_x11=True, fix_x0=True, fix_x15=True,\n",
        "                                  limit_x8=(0,None), limit_x15=(0,None), limit_x16=(0,None), limit_x17=(0,None), limit_x18=(0,None), limit_x19=(0,None), fix_x20 = True, fix_x21=True, fix_x22=True, fix_x23=True, fix_x24=True, fix_x25=True,\n",
        "                                  limit_x9=(0,None), fix_x5=True, fix_x10=True, limit_x11=(-1,1), errordef=1)\n",
        "\n",
        "\n",
        "# Run this to perform the fits using iminuit.\n",
        "c=m_binned.migrad()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' fix_x20 = True, fix_x21=True, fix_x22=True, fix_x23=True, fix_x24=True, fix_x25=True,'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La1GbVAPP3hL"
      },
      "source": [
        "Methods to store the fit values and errors/correlations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnRAJLJME7AP"
      },
      "source": [
        "def write(location, array):\n",
        "    f=open('storedvalues/' + location + '.txt', \"w\")\n",
        "    st = np.array2string(array).replace(' ', '\\t')\n",
        "    st=st.replace('\\t\\t', '\\t')\n",
        "    st=st.replace('\\n\\t', '\\t')\n",
        "    st=st.replace('[', '\\n[')\n",
        "    st=st.replace('\\t\\t', '\\t')\n",
        "    f.write(st)\n",
        "    f.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGaXuH-NE7AR"
      },
      "source": [
        "write(\"214_values\", m_binned.np_values())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzjaMxa0E7AU"
      },
      "source": [
        "write(\"fit_final_ errors\", m_binned.np_errors())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8lHUlfBE7AW"
      },
      "source": [
        "write(\"fit1 correlations\", np.asarray(m_binned.matrix(correlation=True)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaVc7AqnE7Al"
      },
      "source": [
        "write('full fit end v2', m_binned.np_values()[-6:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmBh1eFQE7An"
      },
      "source": [
        "write('full fit errors v2', m_binned.np_errors()[-6:])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}